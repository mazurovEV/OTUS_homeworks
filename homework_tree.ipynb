{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.criterion = criterion\n",
    "        self.max_features = max_features\n",
    "        self.num_class = -1\n",
    "        self.init()\n",
    "    \n",
    "    def init(self):\n",
    "        if self.criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif self.criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif self.criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print 'invalid criterion name'\n",
    "            raise\n",
    "\n",
    "        if self.max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif self.max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif self.max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print 'invalid max_features name'\n",
    "            raise \n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"min_samples_split\": self.min_samples_split, \"max_depth\": self.max_depth, \n",
    "                \"sufficient_share\": self.sufficient_share, \"criterion\": self.criterion, \n",
    "                \"max_features\": self.max_features}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        self.init()\n",
    "        return self\n",
    "    \n",
    "    def __gini(self, l_c, l_s, r_c, r_s, size):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        l_c = l_c/l_s\n",
    "        r_c = r_c/r_s\n",
    "        left_gini = np.diag(l_c.dot((1 - l_c).T))\n",
    "        left_gini = left_gini.reshape(l_s.shape[0], 1)\n",
    "        right_gini = np.diag(r_c.dot((1 - r_c).T))\n",
    "        right_gini = right_gini.reshape(r_s.shape[0], 1)\n",
    "        \n",
    "        return left_gini*l_s/size + right_gini*r_s/size\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s, size):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        l_c = l_c/l_s\n",
    "        r_c = r_c/r_s\n",
    "        left_entropy = -1*np.diag(l_c.dot(np.log((l_c).T)))\n",
    "        left_entropy = left_entropy.reshape(l_s.shape[0], 1)\n",
    "        right_entropy = -1*np.diag(r_c.dot(np.log((r_c).T)))\n",
    "        right_entropy = right_entropy.reshape(r_s.shape[0], 1)\n",
    "        \n",
    "        return left_entropy*l_s/size + right_entropy*r_s/size \n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s, size):\n",
    "        l_c = l_c/l_s\n",
    "        r_c = r_c/r_s\n",
    "        return 1 - np.amax(l_c, axis=1) + 1 - np.amax(r_c, axis=1)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_features):\n",
    "        feature_ids = range(n_features)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[0:max(1, int(np.sqrt(n_features)))]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_features):\n",
    "        feature_ids = range(n_features)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[0:max(1, int(np.log2(n_features)))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_features):\n",
    "        return range(n_features)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        #Сортируем значения фичи по возрастанию с учетом метки класса\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        #Сколько всего классов\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        #Учитываем, что нас интересуют сплиты с размером не меньше min_samples_split\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        #Находим индексы, где меняется класс\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        if len(r_border_ids) == 0:\n",
    "            return [float('+inf'), None]\n",
    "        \n",
    "        # Для каждого разбиения считаем кол-во эл-тов каждого класса(l_class_count, r_class_count)\n",
    "        #Считаем сколько элементов в каком поддереве при каждом разиении(l_sizes, r_sizes)\n",
    "        #Это матрицы, где строки это разбиения, а столбцы это классы\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        #Выбираем то разбиение, для которого самый маленький критерий информативности\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes, y.shape[0])\n",
    "        idx = np.argmin(gs)\n",
    "    \n",
    "        # Возвращаем значение критерия и значение threshold, по которому будем разбивать на поддеревья\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        threshold = (sorted_x[left_el_id + 1] + sorted_x[left_el_id]) / 2.0\n",
    "        if(threshold >= np.max(x)) : \n",
    "            threshold = threshold - 0.5\n",
    "        \n",
    "        return [gs[idx], threshold]\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        \n",
    "        #проверяем критерии останова\n",
    "        if (depth == self.max_depth or self.__count_sufficient_share(y) >= self.sufficient_share or y.shape[0] <= self.min_samples_split):\n",
    "            self.tree[node_id] = (self.__class__.LEAF_TYPE, self.__most_frequent_class(y))\n",
    "        else: \n",
    "            #Находим лучшую фичу для разбиения и ее порог\n",
    "            thresholds = []\n",
    "            for feature_id in self.get_feature_ids(x.shape[1]):\n",
    "                th = self.__find_threshold(x[:, feature_id], y)\n",
    "                th.append(feature_id)\n",
    "                thresholds.append(th)\n",
    "            min_gs = min(thresholds, key = lambda t: t[0])\n",
    "            \n",
    "            #Не удалось найти разбиение - делаем лист\n",
    "            if min_gs[1] is not None:\n",
    "                #Разбиваем выборку на поддеревья\n",
    "                left_x, right_x, left_y, right_y = self.__div_samples(x, y, min_gs[2], min_gs[1])\n",
    "                if(left_x.shape[0] == 0):\n",
    "                    self.tree[node_id] = (self.__class__.LEAF_TYPE, self.__most_frequent_class(right_y))\n",
    "                elif(right_x.shape[0] == 0):\n",
    "                    self.tree[node_id] = (self.__class__.LEAF_TYPE, self.__most_frequent_class(left_y))\n",
    "                else:\n",
    "                    self.tree[node_id] = (self.__class__.NON_LEAF_TYPE, min_gs[2], min_gs[1])\n",
    "                    #Рекурсивно строим дерево\n",
    "                    self.__fit_node(left_x, left_y, 2 * node_id + 1, depth + 1)\n",
    "                    self.__fit_node(right_x, right_y, 2 * node_id + 2, depth + 1)\n",
    "                    \n",
    "            else:\n",
    "                self.tree[node_id] = (self.__class__.LEAF_TYPE, self.__most_frequent_class(y))\n",
    "            \n",
    "    \n",
    "    def __most_frequent_class(self, y):\n",
    "        ones = sum(y)\n",
    "        zeros = y.shape[0] - ones\n",
    "        if(ones >= zeros):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def __count_sufficient_share(self, y):\n",
    "        if(self.__most_frequent_class(y) == 1):\n",
    "            return sum(y)/float(y.shape[0])\n",
    "        else:\n",
    "            return (y.shape[0] - sum(y))/float(y.shape[0])\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120269, 11)"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_depth=3)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2, max_depth = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.7541248798\n",
      "0.17719912529\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933690862227\n",
      "0.93219422965\n",
      "0.92886837948\n",
      "0.934356032261\n",
      "0.9341870037\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933566142845\n",
      "0.934771763532\n",
      "0.931820071506\n",
      "0.928826806352\n",
      "0.932399284912\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['PassengerId','Survived','Name','Ticket','Cabin'], axis=1)\n",
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(x, target, test_size=.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = MyDecisionTreeClassifier(min_samples_split=2, max_depth=3)\n",
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775784753363\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=tree.predict(x_validation), y_true=y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_sc = DecisionTreeClassifier(min_samples_split=2)\n",
    "tree_sc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757847533632\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=tree_sc.predict(x_validation), y_true=y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {'max_features': ['sqrt', 'log2', None], 'criterion': ['gini', 'entropy', 'misclass'],\n",
    "                     'sufficient_share': [0.3, 0.5, 0.7, 1.0], 'max_depth': [3, 5, 7, 10, 15], \n",
    "                    'min_samples_split': [2, 3, 4, 5, 6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:65: RuntimeWarning: divide by zero encountered in log\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:67: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=<__main__.MyDecisionTreeClassifier instance at 0x26e004ab8>,\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': ['sqrt', 'log2', None], 'sufficient_share': [0.3, 0.5, 0.7, 1.0], 'min_samples_split': [2, 3, 4, 5, 6], 'criterion': ['gini', 'entropy', 'misclass'], 'max_depth': [3, 5, 7, 10, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = MyDecisionTreeClassifier()\n",
    "clf = GridSearchCV(tree, tuned_parameters, cv=5, scoring='accuracy')\n",
    "clf.fit(x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_split': 2,\n",
       " 'sufficient_share': 1.0}"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789237668161\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=clf.best_estimator_.predict(x_validation), y_true=y_validation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
